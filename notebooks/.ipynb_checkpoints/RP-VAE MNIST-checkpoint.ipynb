{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ecea28",
   "metadata": {},
   "source": [
    "# Recognition-parametrized Variational autoencoders\n",
    "- $p_\\theta(\\mathcal{X},\\mathcal{Z})$ is a conditionally normalized RPM, whereas $q_\\psi(\\mathcal{Z} | \\mathcal{X})$ is from a jointly normalized RPM\n",
    "\n",
    "- all RPMS conditionally independent !\n",
    "\n",
    "- here application to MNIST, i.e. $p_\\theta(\\mathcal{Z})$ and $f_{\\theta_j}(\\mathcal{Z}| \\bf{x}_j)$ are categorical for each $j =1, 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "root = './data/MNIST'\n",
    "ds0train = torchvision.datasets.MNIST(root=root, train=True)\n",
    "ds0test = torchvision.datasets.MNIST(root=root, train=False)\n",
    "\n",
    "class Peersupervision(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, J, ifstack=True):\n",
    "        self.data = data\n",
    "        self.targets = targets.detach().numpy()\n",
    "        self.J = J\n",
    "        self.ifstack = ifstack\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        c = self.targets[idx]\n",
    "        if c.ndim==0:\n",
    "            idc = np.where(self.targets==c)[0]\n",
    "            pair_ids = idc[np.random.choice(len(idc), self.J+1, replace=False).reshape(1,-1)]\n",
    "            pair_ids[0,0] = idx\n",
    "        else:\n",
    "            pair_ids = np.zeros((len(idx), self.J))\n",
    "            for i,c_ in enumerate(c):\n",
    "                idc = np.where(self.targets==c_)[0]\n",
    "                pair_ids[i] = idc[np.random.choice(len(idc), self.J, replace=False)]\n",
    "            pair_ids[:,0] = idx\n",
    "\n",
    "        out = [self.data[pair_ids[:,j]] for j in range(self.J)]\n",
    "        return torch.stack(out,axis=1) if self.ifstack else out \n",
    "\n",
    "N,J = len(ds0train), 2\n",
    "\n",
    "ds_train = Peersupervision(data=ds0train.data/256., targets=ds0train.targets, J=J, ifstack=False)\n",
    "train_data = ds_train[np.arange(N)]\n",
    "train_labels = ds0train.targets\n",
    "\n",
    "ds_test = Peersupervision(data=ds0test.data/256., targets=ds0test.targets, J=J, ifstack=False)\n",
    "test_data = ds_test[np.arange(len(ds0test))]\n",
    "test_labels = ds0test.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01632302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(np.minimum(N, 5)):\n",
    "    for i in range(J):\n",
    "        plt.subplot(np.minimum(N, 5), J, J*n + i + 1)\n",
    "        data_show = train_data[n,i].detach().numpy() if ds_train.ifstack else train_data[i][n].detach().numpy()\n",
    "        plt.imshow(data_show)\n",
    "        plt.axis('off')\n",
    "plt.suptitle('First ' + str(np.minimum(N, 5)) + ' out of N= ' +str(N) + ' peer tuples of size J =' +str(J))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c8604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rpm import RPMEmpiricalMarginals, EmpiricalDistribution\n",
    "from discreteRPM import discreteRPVAE, discretenonCondIndRPM, Prior_discrete, RecognitionFactor_discrete\n",
    "from implicitRPM import ObservedMarginal, IndependentMarginal, GaussianCopula_ExponentialMarginals\n",
    "\n",
    "from discreteRPM import discreteRPM, discretenonCondIndRPM, Prior_discrete, RecognitionFactor_scaled_discrete\n",
    "\n",
    "K = len(np.unique(train_labels.detach().numpy()))\n",
    "dim_T = K # dimension of sufficient statistics\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    # Convolutional Neural Network shared across independent factors\n",
    "    def __init__(self, C_in, n_out, C_hidden, n_hidden, activation_out=torch.nn.Identity()):\n",
    "        super(Net, self).__init__()\n",
    "        self.activation_out = activation_out\n",
    "        self.conv1 = torch.nn.Conv2d(C_in, C_hidden, kernel_size=5)\n",
    "        self.conv2 =torch.nn.Conv2d(C_hidden, 2*C_hidden, kernel_size=5)\n",
    "        self.conv2_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(4*4*2*C_hidden, n_hidden)\n",
    "        self.fc2 = torch.nn.Linear(n_hidden, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(torch.nn.functional.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.nn.functional.relu(torch.nn.functional.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 4*4*20)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.activation_out(x)\n",
    "\n",
    "\n",
    "natparam_models = [Net(C_in=1, n_out=K, C_hidden=10, n_hidden=50, activation_out=torch.nn.Identity()) for j in range(J)]\n",
    "rec_models = [RecognitionFactor_discrete(model=m) for m in natparam_models]\n",
    "\n",
    "prior =  Prior_discrete(param=torch.zeros(size=(K,)))\n",
    "\n",
    "\n",
    "xjs = [train_data[:,j] for j in range(J)] if ds_train.ifstack else [train_data[j] for j in range(J)]\n",
    "pxj = RPMEmpiricalMarginals(xjs)\n",
    "\n",
    "# constsruct implicit RPM\n",
    "full_F = False\n",
    "drpm = discreteRPVAE(rec_models, \n",
    "                     latent_prior=prior, \n",
    "                     pxjs=xjs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.param_.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da85298",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.param_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3d35b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "optimizer = torch.optim.Adam(drpm.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "ds_load = torch.utils.data.TensorDataset(*train_data) if ds_train.ifstack else torch.utils.data.TensorDataset(*train_data)\n",
    "dl = torch.utils.data.DataLoader(dataset=ds_load, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "ls,t = np.zeros(epochs*(N//batch_size)),0\n",
    "for i in range(epochs):\n",
    "    for batch in dl:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch[0] if ds_train.ifstack else [x.unsqueeze(1) for x in batch]\n",
    "        loss = drpm.training_step(batch, batch_idx=t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ls[t] = loss.detach().numpy()\n",
    "        t+=1\n",
    "    print('epoch #' + str(i+1) + '/' + str(epochs) + ', loss : ' + str(ls[t-1]))\n",
    "plt.plot(ls)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c96687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "posts = torch.exp(drpm.eval([td.unsqueeze(1) for td in train_data])[1]).detach().numpy()\n",
    "\n",
    "M = skmetrics.confusion_matrix(y_true=np.argmax(posts,axis=1), y_pred=train_labels)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64191a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapij(a):\n",
    "    b = np.zeros_like(a)\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == 0:\n",
    "            b[i] =   5\n",
    "        if a[i] == 1:\n",
    "            b[i] =   4\n",
    "        if a[i] == 2:\n",
    "            b[i] =   2\n",
    "        if a[i] == 3:\n",
    "            b[i] =   3\n",
    "        if a[i] == 4:\n",
    "            b[i] =   6\n",
    "        if a[i] == 5:\n",
    "            b[i] =   9\n",
    "        if a[i] == 6:\n",
    "            b[i] =   7\n",
    "        if a[i] == 7:\n",
    "            b[i] =   0\n",
    "        if a[i] == 8:\n",
    "            b[i] =   8\n",
    "        if a[i] == 9:\n",
    "            b[i] =   1\n",
    "    return b\n",
    "\n",
    "Mperm = skmetrics.confusion_matrix(y_true=mapij(np.argmax(posts,axis=1)), y_pred=train_labels)\n",
    "plt.imshow(Mperm)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "np.diag(Mperm).sum() / Mperm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c10459",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = torch.exp(drpm.eval([td.unsqueeze(1) for td in test_data])[1]).detach().numpy()\n",
    "\n",
    "M = skmetrics.confusion_matrix(y_true=np.argmax(posts,axis=1), y_pred=test_labels)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "Mperm = skmetrics.confusion_matrix(y_true=mapij(np.argmax(posts,axis=1)), y_pred=test_labels)\n",
    "plt.imshow(Mperm)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "np.diag(Mperm).sum() / Mperm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c54d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
