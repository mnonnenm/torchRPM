{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ecea28",
   "metadata": {},
   "source": [
    "# RPM without conditional independence assumption\n",
    "- dependency structure is overrated !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "root = './data/MNIST'\n",
    "ds0train = torchvision.datasets.MNIST(root=root, train=True)\n",
    "ds0test = torchvision.datasets.MNIST(root=root, train=False)\n",
    "\n",
    "class Peersupervision(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, J, ifstack=True):\n",
    "        self.data = data\n",
    "        self.targets = targets.detach().numpy()\n",
    "        self.J = J\n",
    "        self.ifstack = ifstack\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        c = self.targets[idx]\n",
    "        if c.ndim==0:\n",
    "            idc = np.where(self.targets==c)[0]\n",
    "            pair_ids = idc[np.random.choice(len(idc), self.J+1, replace=False).reshape(1,-1)]\n",
    "            pair_ids[0,0] = idx\n",
    "        else:\n",
    "            pair_ids = np.zeros((len(idx), self.J))\n",
    "            for i,c_ in enumerate(c):\n",
    "                idc = np.where(self.targets==c_)[0]\n",
    "                pair_ids[i] = idc[np.random.choice(len(idc), self.J, replace=False)]\n",
    "            pair_ids[:,0] = idx\n",
    "\n",
    "        out = [self.data[pair_ids[:,j]] for j in range(self.J)]\n",
    "        return torch.stack(out,axis=1) if self.ifstack else out \n",
    "\n",
    "N,J = len(ds0train), 2\n",
    "\n",
    "ds_train = Peersupervision(data=ds0train.data/256., targets=ds0train.targets, J=J, ifstack=True)\n",
    "train_data = ds_train[np.arange(N)]\n",
    "train_labels = ds0train.targets\n",
    "\n",
    "ds_test = Peersupervision(data=ds0test.data/256., targets=ds0test.targets, J=J, ifstack=True)\n",
    "test_data = ds_test[np.arange(len(ds0test))]\n",
    "test_labels = ds0test.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01632302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(np.minimum(N, 5)):\n",
    "    for i in range(J):\n",
    "        plt.subplot(np.minimum(N, 5), J, J*n + i + 1)\n",
    "        data_show = train_data[n,i].detach().numpy() if ds_train.ifstack else train_data[i][n].detach().numpy()\n",
    "        plt.imshow(data_show)\n",
    "        plt.axis('off')\n",
    "plt.suptitle('First ' + str(np.minimum(N, 5)) + ' out of N= ' +str(N) + ' peer tuples of size J =' +str(J))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c8604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rpm import RPMEmpiricalMarginals, EmpiricalDistribution\n",
    "from discreteRPM import discreteRPM, discretenonCondIndRPM, Prior_discrete, RecognitionFactor_discrete\n",
    "from implicitRPM import ObservedMarginal, IndependentMarginal, GaussianCopula_ExponentialMarginals\n",
    "\n",
    "from discreteRPM import discreteRPM, discretenonCondIndRPM, Prior_discrete, RecognitionFactor_scaled_discrete\n",
    "\n",
    "K = len(np.unique(train_labels.detach().numpy()))\n",
    "dim_T = K # dimension of sufficient statistics\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    # Convolutional Neural Network shared across independent factors\n",
    "    def __init__(self, C_in, n_out, C_hidden, n_hidden, activation_out=torch.nn.Identity()):\n",
    "        super(Net, self).__init__()\n",
    "        self.activation_out = activation_out\n",
    "        self.conv1 = torch.nn.Conv2d(C_in, C_hidden, kernel_size=5)\n",
    "        self.conv2 =torch.nn.Conv2d(C_hidden, 2*C_hidden, kernel_size=5)\n",
    "        self.conv2_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(4*4*2*C_hidden, n_hidden)\n",
    "        self.fc2 = torch.nn.Linear(n_hidden, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(torch.nn.functional.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.nn.functional.relu(torch.nn.functional.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 4*4*20)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.activation_out(x)\n",
    "\n",
    "\n",
    "#natparam_model = Net(C_in=J, n_out=K, C_hidden=10, n_hidden=50, activation_out=torch.nn.Identity())\n",
    "#rec_model = RecognitionFactor_discrete(model=natparam_model) \n",
    "\n",
    "natparam_model = Net(C_in=J, n_out=K+1, C_hidden=10, n_hidden=50, activation_out=torch.nn.Identity())\n",
    "rec_model = RecognitionFactor_scaled_discrete(model=natparam_model) \n",
    "\n",
    "\n",
    "prior =  Prior_discrete(param=torch.zeros(size=(K,)))\n",
    "\n",
    "\n",
    "xjs = [train_data[:,j] for j in range(J)] if ds_train.ifstack else [train_data[j] for j in range(J)]\n",
    "pxj = RPMEmpiricalMarginals(xjs)\n",
    "\n",
    "# constsruct implicit RPM\n",
    "full_F = False\n",
    "drpm = discretenonCondIndRPM(rec_model, \n",
    "                             latent_prior=prior, \n",
    "                             pxjs=pxj, \n",
    "                             full_F=full_F)\n",
    "\n",
    "\"\"\"\n",
    "natparam_models = [Net(C_in=1, n_out=K, C_hidden=10, n_hidden=50, activation_out=torch.nn.Identity()) for j in range(J)]\n",
    "rec_models = [RecognitionFactor_discrete(model=m) for m in natparam_models] \n",
    "\n",
    "# constsruct implicit RPM\n",
    "drpm = discreteRPM(rec_models, \n",
    "                      latent_prior=Prior_discrete(param=torch.randn(size=(K,))), \n",
    "                      pxjs=xjs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.param_.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da85298",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.param_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3d35b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "optimizer = torch.optim.Adam(drpm.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "ds_load = torch.utils.data.TensorDataset(train_data) if ds_train.ifstack else torch.utils.data.TensorDataset(*train_data)\n",
    "dl = torch.utils.data.DataLoader(dataset=ds_load, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "ls,t = np.zeros(epochs*(N//batch_size)),0\n",
    "for i in range(epochs):\n",
    "    for batch in dl:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch[0] if ds_train.ifstack else [x.unsqueeze(1) for x in batch]\n",
    "        loss = drpm.training_step(batch, batch_idx=t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ls[t] = loss.detach().numpy()\n",
    "        t+=1\n",
    "    print('epoch #' + str(i+1) + '/' + str(epochs) + ', loss : ' + str(ls[t-1]))\n",
    "plt.plot(ls)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80248aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "ls,t = np.zeros(epochs*(N//batch_size)),0\n",
    "for i in range(epochs):\n",
    "    for batch in dl:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch[0] if ds_train.ifstack else [x.unsqueeze(1) for x in batch]\n",
    "        loss = drpm.training_step(batch, batch_idx=t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ls[t] = loss.detach().numpy()\n",
    "        t+=1\n",
    "    print('epoch #' + str(i+1) + '/' + str(epochs) + ', loss : ' + str(ls[t-1]))\n",
    "plt.plot(ls)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_est_F = 200\n",
    "idx_sort=np.argsort(train_labels[:N_est_F].detach().numpy())\n",
    "all_xjs = [pxj.x[:N_est_F][idx_sort] for pxj in drpm.pxjs.pxjs]\n",
    "N_ = all_xjs[0].shape[0]\n",
    "assert all([N_ == xj.shape[0] for xj in all_xjs])\n",
    "shuffle_ids = torch.cartesian_prod(*[torch.arange(N_,dtype=torch.int) for j in range(J)])\n",
    "xshuffled = torch.stack([all_xjs[j][shuffle_ids[:,j]] for j in range(J)], axis=1) # N^J-J-K !!!!\n",
    "m = drpm.rec_model\n",
    "log_fxs = m.log_probs(xshuffled)                                         # N^J - K \n",
    "log_denom = torch.logsumexp(log_fxs,dim=0).reshape(1,-1) - np.log(N_**J) #  1  - K\n",
    "pOverF = (torch.exp(drpm.latent_prior.log_probs()).reshape(1,-1)/torch.exp(log_denom).reshape(1,-1)).detach().numpy()\n",
    "\n",
    "plt.plot(torch.exp(log_denom[0]).detach().numpy(), label='F(Z) (est. from subsample)')\n",
    "plt.plot(torch.exp(drpm.latent_prior.log_probs()).detach().numpy(), label='P(Z))')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "posts = torch.exp(drpm.rec_model(train_data)).detach().numpy()\n",
    "for c in range(10):\n",
    "    idx = np.where(train_labels==c)\n",
    "    plt.subplot(5,2,c+1)\n",
    "    plt.plot((posts[idx]*pOverF).mean(axis=0))\n",
    "    plt.ylabel('c='+str(c+1))\n",
    "plt.suptitle('avg. posteriors per class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8ff05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(torch.exp(log_fxs).sum(axis=-1).reshape(N_est_F, N_est_F).detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7662e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "plt.figure(figsize=(16,16))\n",
    "for k in range(K):\n",
    "    plt.subplot(4,3,k+1)\n",
    "    plt.imshow(torch.exp(log_fxs[:,k]).reshape(N_est_F, N_est_F).detach().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = (torch.exp(drpm.rec_model(train_data)) ).detach().numpy() * pOverF\n",
    "for m in range(10):\n",
    "    for n in range(5):\n",
    "        for i in range(J):\n",
    "            plt.subplot(5, J+1, (J+1)*n + i + 1)\n",
    "            plt.imshow(train_data[m*5+n,i].detach().numpy())            \n",
    "            plt.axis('off')\n",
    "        plt.subplot(5, J+1, (J+1)*n + 3)\n",
    "        plt.plot(np.arange(K)+1, posts[m*5+n])\n",
    "                 #torch.exp(drpm.rec_model(train_data[m*5+n].reshape(1,*train_data[m*5+n].shape)))[0].detach().numpy())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c96687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "posts = (torch.exp(drpm.rec_model(train_data)) ).detach().numpy() * pOverF\n",
    "\n",
    "M = skmetrics.confusion_matrix(y_true=np.argmax(posts,axis=1), y_pred=train_labels)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#(M[3,0] + M[1,1] + M[2,2] + M[5,3] + M[4,4] + M[6,5] + M[7,6] + M[9,7] + M[8,8] + M[9,9]) / M.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64191a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapij(a):\n",
    "    b = np.zeros_like(a)\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == 0:\n",
    "            b[i] =   5\n",
    "        if a[i] == 1:\n",
    "            b[i] =   2\n",
    "        if a[i] == 2:\n",
    "            b[i] =   7\n",
    "        if a[i] == 3:\n",
    "            b[i] =   8\n",
    "        if a[i] == 4:\n",
    "            b[i] =   9\n",
    "        if a[i] == 5:\n",
    "            b[i] =   4\n",
    "        if a[i] == 6:\n",
    "            b[i] =   6\n",
    "        if a[i] == 7:\n",
    "            b[i] =   0\n",
    "        if a[i] == 8:\n",
    "            b[i] =   1\n",
    "        if a[i] == 9:\n",
    "            b[i] =   3\n",
    "    return b\n",
    "\n",
    "Mperm = skmetrics.confusion_matrix(y_true=mapij(np.argmax(posts,axis=1)), y_pred=train_labels)\n",
    "plt.imshow(Mperm)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "np.diag(Mperm).sum() / Mperm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c10459",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = (torch.exp(drpm.rec_model(test_data)) ).detach().numpy() * pOverF\n",
    "\n",
    "M = skmetrics.confusion_matrix(y_true=np.argmax(posts,axis=1), y_pred=test_labels)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "Mperm = skmetrics.confusion_matrix(y_true=mapij(np.argmax(posts,axis=1)), y_pred=test_labels)\n",
    "plt.imshow(Mperm)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "np.diag(Mperm).sum() / Mperm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf440f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
