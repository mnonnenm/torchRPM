{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e18a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "root = './data/MNIST'\n",
    "ds0train = torchvision.datasets.MNIST(root=root, train=True)\n",
    "ds0test = torchvision.datasets.MNIST(root=root, train=False)\n",
    "\n",
    "dtype=torch.float32\n",
    "\n",
    "def rotate(images):\n",
    "    batch_size = len(images)\n",
    "    angles= [0, 120, 240]\n",
    "    idx = np.random.randint(0, len(angles), batch_size)\n",
    "    with torch.no_grad(): \n",
    "        out = torch.stack([TF.rotate(images[i].unsqueeze(0), angles[idx[i]])[0] for i in range(batch_size)],dim=0)\n",
    "    return out\n",
    "\n",
    "def colorize(images):\n",
    "    batch_size = len(images)\n",
    "    colors = np.array(\n",
    "        [[166,206,227],\n",
    "         [31,120,180],\n",
    "         [178,223,138],\n",
    "         [51,160,44],\n",
    "         [251,154,153]],\n",
    "    )/256.\n",
    "    colors = np.asarray(colors,dtype=np.float32)\n",
    "    idx = np.random.randint(0, len(colors), batch_size)\n",
    "    with torch.no_grad():\n",
    "        out=torch.stack([(images[i].unsqueeze(0).repeat(3,1,1)*colors[idx[i]].reshape(-1,1,1)) for i in range(batch_size)],dim=0) \n",
    "\n",
    "    return out\n",
    "\n",
    "transforms_j = rotate, colorize\n",
    "\n",
    "class Peersupervision(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, J, transforms, ifstack=True):\n",
    "        self.data = data\n",
    "        self.targets = targets.detach().numpy()\n",
    "        self.J = J\n",
    "        self.ifstack = ifstack\n",
    "        assert len(transforms) == J\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        c = self.targets[idx]\n",
    "        if c.ndim==0:\n",
    "            idc = np.where(self.targets==c)[0]\n",
    "            pair_ids = idc[np.random.choice(len(idc), self.J+1, replace=False).reshape(1,-1)]\n",
    "            pair_ids[0,0] = idx\n",
    "        else:\n",
    "            pair_ids = np.zeros((len(idx), self.J))\n",
    "            for i,c_ in enumerate(c):\n",
    "                idc = np.where(self.targets==c_)[0]\n",
    "                pair_ids[i] = idc[np.random.choice(len(idc), self.J, replace=False)]\n",
    "            pair_ids[:,0] = idx\n",
    "\n",
    "        out = [self.transforms[j](self.data[pair_ids[:,j]]) for j in range(self.J)]\n",
    "        return (torch.stack(out,axis=1), idx) if self.ifstack else (out, idx) \n",
    "\n",
    "N,J = len(ds0train), 2\n",
    "\n",
    "ds_train = Peersupervision(data=ds0train.data/256., targets=ds0train.targets, J=J, transforms=transforms_j,ifstack=False)\n",
    "train_data = ds_train[np.arange(N)]\n",
    "train_data = [[train_data[0][0].unsqueeze(1), train_data[0][1]], train_data[1]]\n",
    "train_labels = ds0train.targets\n",
    "\n",
    "ds_test = Peersupervision(data=ds0test.data/256., targets=ds0test.targets, J=J, transforms=transforms_j, ifstack=False)\n",
    "test_data = ds_test[np.arange(len(ds0test))]\n",
    "test_data = [[test_data[0][0].unsqueeze(1), test_data[0][1]], test_data[1]]\n",
    "test_labels = ds0test.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,6))\n",
    "for n in range(np.minimum(N, 5)):\n",
    "    for j in range(J):\n",
    "        plt.subplot(np.minimum(N, 5), J, J*n + j + 1)\n",
    "        data_show = train_data[0][n,j].detach().numpy() if ds_train.ifstack else train_data[0][j][n].detach().numpy()\n",
    "        if j == 0:\n",
    "            plt.imshow(data_show[0], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(data_show.transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "plt.suptitle('First ' + str(np.minimum(N, 5)) + ' out of N= ' +str(N) + ' peer tuples of size J =' +str(J))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c42d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpm import RPMEmpiricalMarginals, EmpiricalDistribution\n",
    "from discreteRPM import discreteRPM_localLatents, Prior_discrete\n",
    "from implicitRPM import ObservedMarginal, IndependentMarginal\n",
    "from discreteRPM import RecognitionFactor_discrete, RecognitionFactor_zj_discrete\n",
    "from discreteRPM import WeightedEmpiricalDistribution, WeightModel, EmpWeightModel_RPM, RPMWeightedEmpiricalMarginals\n",
    "\n",
    "\n",
    "K = len(np.unique(train_labels.detach().numpy()))\n",
    "dim_T = K # dimension of sufficient statistics\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    # Convolutional Neural Network shared across independent factors\n",
    "    def __init__(self, C_in, n_out, C_hidden, n_hidden, activation_out=torch.nn.Identity()):\n",
    "        super(Net, self).__init__()\n",
    "        self.activation_out = activation_out\n",
    "        self.conv1 = torch.nn.Conv2d(C_in, C_hidden, kernel_size=5)\n",
    "        self.conv2 =torch.nn.Conv2d(C_hidden, 2*C_hidden, kernel_size=5)\n",
    "        self.conv2_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(4*4*2*C_hidden, n_hidden)\n",
    "        self.fc2 = torch.nn.Linear(n_hidden, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(torch.nn.functional.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.nn.functional.relu(torch.nn.functional.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 4*4*20)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.activation_out(x)\n",
    "\n",
    "C_ins_j = [1,3] # number of input channels (per j) for CNNs\n",
    "K_j = [3, 5] # number of latent states for local latents\n",
    "\n",
    "natparam_models = [Net(C_in=C_ins_j[j], \n",
    "                       n_out=K*K_j[j], \n",
    "                       C_hidden=10, \n",
    "                       n_hidden=50, \n",
    "                       activation_out=torch.nn.Identity()) for j in range(J)]\n",
    "rec_models = [RecognitionFactor_zj_discrete(model=natparam_models[j], K=K_j[j]) for j in range(J)]\n",
    "\n",
    "\n",
    "prior_g =  Prior_discrete(param=torch.zeros(size=(K,)))\n",
    "priors_j = [Prior_discrete(param=torch.zeros(size=(K_j[j],))) for j in range(J)]\n",
    "\n",
    "xjs = [train_data[0][j] for j in range(J)]\n",
    "\n",
    "# saturated models alpha_j(n | zj) = Softmax(Mj tj(zj)) for one-hot zj within tj(zj), i.e. one row of Mj per n !\n",
    "#emp_weight_models = [WeightModel(M=torch.nn.parameter.Parameter(torch.zeros((K_j[j], N)))) for j in range(J)]\n",
    "\n",
    "# define each h(xj|zj) as another (discrete) RPM - makes things amortized, but quite expensive !\n",
    "emp_weight_param_models = [\n",
    "    Net(C_in=C_ins_j[j], \n",
    "        n_out=K_j[j], \n",
    "        C_hidden=10, \n",
    "        n_hidden=50, \n",
    "        activation_out=torch.nn.Identity()) for j in range(J)]\n",
    "emp_weight_models = [EmpWeightModel_RPM(model=emp_weight_param_models[j], x=xjs[j]) for j in range(J)]\n",
    "\n",
    "\n",
    "pxjs = [WeightedEmpiricalDistribution(model=emp_weight_models[j],x=xjs[j]) for j in range(J)]\n",
    "px_allj = RPMWeightedEmpiricalMarginals(pxjs)\n",
    "\n",
    "# constsruct implicit RPM\n",
    "full_F = False\n",
    "drpm = discreteRPM_localLatents(rec_models, latent_prior_g=prior_g, latent_priors_j=priors_j, px_alljs=px_allj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6174f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "optimizer = torch.optim.Adam(drpm.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "ds_load = torch.utils.data.TensorDataset(*train_data[0], torch.tensor(train_data[1]))\n",
    "dl = torch.utils.data.DataLoader(dataset=ds_load, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "ls,t = np.zeros(epochs*(N//batch_size)),0\n",
    "for i in range(epochs):\n",
    "    for batch in dl:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch[0] if ds_train.ifstack else ((batch[0], batch[1]), batch[2])\n",
    "        loss = drpm.training_step(batch, batch_idx=t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ls[t] = loss.detach().numpy()\n",
    "        t+=1\n",
    "        print(t)\n",
    "    print('epoch #' + str(i+1) + '/' + str(epochs) + ', loss : ' + str(ls[t-1]))\n",
    "plt.plot(ls)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f650c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "xjs = [train_data[0][j] for j in range(J)]\n",
    "idx_n = train_data[1].reshape(-1,1)\n",
    "\n",
    "log_pzj_xs, log_pzg_x, log_px = drpm.eval(xjs, idx_n)\n",
    "posts = log_pzg_x.detach().numpy() # posteriors over global (!) latent\n",
    "\n",
    "M = skmetrics.confusion_matrix(y_true=np.argmax(posts,axis=1), y_pred=train_labels)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapij(a):\n",
    "    b = np.zeros_like(a)\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == 0:\n",
    "            b[i] =   2\n",
    "        if a[i] == 1:\n",
    "            b[i] =   6\n",
    "        if a[i] == 2:\n",
    "            b[i] =   1\n",
    "        if a[i] == 3:\n",
    "            b[i] =   8\n",
    "        if a[i] == 4:\n",
    "            b[i] =   4\n",
    "        if a[i] == 5:\n",
    "            b[i] =   3\n",
    "        if a[i] == 6:\n",
    "            b[i] =   5\n",
    "        if a[i] == 7:\n",
    "            b[i] =   0\n",
    "        if a[i] == 8:\n",
    "            b[i] =   9\n",
    "        if a[i] == 9:\n",
    "            b[i] =   7\n",
    "    return b\n",
    "\n",
    "Mperm = skmetrics.confusion_matrix(y_true=mapij(np.argmax(posts,axis=1)), y_pred=train_labels)\n",
    "plt.imshow(Mperm)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "np.diag(Mperm).sum() / Mperm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37381b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "xjs = [test_data[0][j] for j in range(J)]\n",
    "idx_n = test_data[1].reshape(-1,1)\n",
    "log_pzj_xs, log_pzg_x, log_px = drpm.eval(xjs, idx_n)\n",
    "posts = log_pzg_x.detach().numpy() # posteriors over global (!) latent\n",
    "\n",
    "M = skmetrics.confusion_matrix(y_true=np.argmax(posts,axis=1), y_pred=test_labels)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "Mperm = skmetrics.confusion_matrix(y_true=mapij(np.argmax(posts,axis=1)), y_pred=test_labels)\n",
    "plt.imshow(Mperm)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "np.diag(Mperm).sum() / Mperm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28d30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
